
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="This repository contains the Python Emission Localization and Quantification software we call pyELQ. It is code used for gas dispersion modelling, in particular methane emissions detection, localization and quantification.">
      
      
        <meta name="author" content="pyELQ">
      
      
      
        <link rel="prev" href="../dispersion_model/gaussian_plume/">
      
      
        <link rel="next" href="../gas_species/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.15">
    
    
      
        <title>DLM - pyELQ Python Emission Localization and Quantification</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.342714a4.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


  
  
    
    
      
    
    
  
  
  <style>:root{.md-tag.md-tag--pipelines{--md-tag-icon:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%20640%20512%22%3E%3C%21--%21%20Font%20Awesome%20Free%206.7.2%20by%20%40fontawesome%20-%20https%3A//fontawesome.com%20License%20-%20https%3A//fontawesome.com/license/free%20%28Icons%3A%20CC%20BY%204.0%2C%20Fonts%3A%20SIL%20OFL%201.1%2C%20Code%3A%20MIT%20License%29%20Copyright%202024%20Fonticons%2C%20Inc.--%3E%3Cpath%20d%3D%22M128%2072a24%2024%200%201%201%200%2048%2024%2024%200%201%201%200-48m32%2097.3c28.3-12.3%2048-40.5%2048-73.3%200-44.2-35.8-80-80-80S48%2051.8%2048%2096c0%2032.8%2019.7%2061%2048%2073.3V224H32c-17.7%200-32%2014.3-32%2032s14.3%2032%2032%2032h256v54.7c-28.3%2012.3-48%2040.5-48%2073.3%200%2044.2%2035.8%2080%2080%2080s80-35.8%2080-80c0-32.8-19.7-61-48-73.3V288h256c17.7%200%2032-14.3%2032-32s-14.3-32-32-32h-64v-54.7c28.3-12.3%2048-40.5%2048-73.3%200-44.2-35.8-80-80-80s-80%2035.8-80%2080c0%2032.8%2019.7%2061%2048%2073.3V224H160zM488%2096a24%2024%200%201%201%2048%200%2024%2024%200%201%201-48%200M320%20392a24%2024%200%201%201%200%2048%2024%2024%200%201%201%200-48%22/%3E%3C/svg%3E');}}</style>

    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="custom" data-md-color-accent="custom">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#dlm" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="pyELQ Python Emission Localization and Quantification" class="md-header__button md-logo" aria-label="pyELQ Python Emission Localization and Quantification" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            pyELQ Python Emission Localization and Quantification
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              DLM
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="custom" data-md-color-accent="custom"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="custom" data-md-color-accent="custom"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/sede-open/pyELQ" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    pyELQ
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    
    
      
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../component/component/" class="md-tabs__link">
          
  
  
    
  
  pyELQ User Guide

        </a>
      </li>
    
  

    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="pyELQ Python Emission Localization and Quantification" class="md-nav__button md-logo" aria-label="pyELQ Python Emission Localization and Quantification" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    pyELQ Python Emission Localization and Quantification
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/sede-open/pyELQ" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    pyELQ
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    pyELQ User Guide
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            pyELQ User Guide
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1" >
        
          
          <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Components
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1">
            <span class="md-nav__icon md-icon"></span>
            Components
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../component/component/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../component/background/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Background
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../component/error_model/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Error Model
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../component/offset/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Offset
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../component/source_model/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Source Model
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../coordinate_system/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Coordinate System
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../data_access/data_access/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Data Access
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dispersion_model/gaussian_plume/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Dispersion Model
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    DLM
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    DLM
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#pyelq.dlm" class="md-nav__link">
    <span class="md-ellipsis">
      dlm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pyelq.dlm.DLM" class="md-nav__link">
    <span class="md-ellipsis">
      DLM
    </span>
  </a>
  
    <nav class="md-nav" aria-label="DLM">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pyelq.dlm.DLM.nof_observables" class="md-nav__link">
    <span class="md-ellipsis">
      nof_observables
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pyelq.dlm.DLM.nof_state_parameters" class="md-nav__link">
    <span class="md-ellipsis">
      nof_state_parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pyelq.dlm.DLM.calculate_g_power" class="md-nav__link">
    <span class="md-ellipsis">
      calculate_g_power
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pyelq.dlm.DLM.polynomial_f_g" class="md-nav__link">
    <span class="md-ellipsis">
      polynomial_f_g
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pyelq.dlm.DLM.simulate_data" class="md-nav__link">
    <span class="md-ellipsis">
      simulate_data
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pyelq.dlm.DLM.forecast_mean" class="md-nav__link">
    <span class="md-ellipsis">
      forecast_mean
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pyelq.dlm.DLM.forecast_covariance" class="md-nav__link">
    <span class="md-ellipsis">
      forecast_covariance
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pyelq.dlm.DLM.update_posterior" class="md-nav__link">
    <span class="md-ellipsis">
      update_posterior
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pyelq.dlm.DLM.dlm_full_update" class="md-nav__link">
    <span class="md-ellipsis">
      dlm_full_update
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pyelq.dlm.DLM.calculate_mahalanobis_distance" class="md-nav__link">
    <span class="md-ellipsis">
      calculate_mahalanobis_distance
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pyelq.dlm.DLM.create_full_covariance" class="md-nav__link">
    <span class="md-ellipsis">
      create_full_covariance
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pyelq.dlm.mahalanobis_distance" class="md-nav__link">
    <span class="md-ellipsis">
      mahalanobis_distance
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gas_species/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Gas Species
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../meteorology/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Meteorology
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../model/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Model
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../plotting/plot/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Plotting
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../preprocessing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Pre-Processing
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_11" >
        
          
          <label class="md-nav__link" for="__nav_2_11" id="__nav_2_11_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Sensor
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_11">
            <span class="md-nav__icon md-icon"></span>
            Sensor
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sensor/sensor/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sensor/beam/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Beam
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sensor/satellite/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Satellite
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../source_map/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Source Map
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../support_functions/spatio_temporal_interpolation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Support Functions
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#pyelq.dlm" class="md-nav__link">
    <span class="md-ellipsis">
      dlm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pyelq.dlm.DLM" class="md-nav__link">
    <span class="md-ellipsis">
      DLM
    </span>
  </a>
  
    <nav class="md-nav" aria-label="DLM">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pyelq.dlm.DLM.nof_observables" class="md-nav__link">
    <span class="md-ellipsis">
      nof_observables
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pyelq.dlm.DLM.nof_state_parameters" class="md-nav__link">
    <span class="md-ellipsis">
      nof_state_parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pyelq.dlm.DLM.calculate_g_power" class="md-nav__link">
    <span class="md-ellipsis">
      calculate_g_power
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pyelq.dlm.DLM.polynomial_f_g" class="md-nav__link">
    <span class="md-ellipsis">
      polynomial_f_g
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pyelq.dlm.DLM.simulate_data" class="md-nav__link">
    <span class="md-ellipsis">
      simulate_data
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pyelq.dlm.DLM.forecast_mean" class="md-nav__link">
    <span class="md-ellipsis">
      forecast_mean
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pyelq.dlm.DLM.forecast_covariance" class="md-nav__link">
    <span class="md-ellipsis">
      forecast_covariance
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pyelq.dlm.DLM.update_posterior" class="md-nav__link">
    <span class="md-ellipsis">
      update_posterior
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pyelq.dlm.DLM.dlm_full_update" class="md-nav__link">
    <span class="md-ellipsis">
      dlm_full_update
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pyelq.dlm.DLM.calculate_mahalanobis_distance" class="md-nav__link">
    <span class="md-ellipsis">
      calculate_mahalanobis_distance
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pyelq.dlm.DLM.create_full_covariance" class="md-nav__link">
    <span class="md-ellipsis">
      create_full_covariance
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pyelq.dlm.mahalanobis_distance" class="md-nav__link">
    <span class="md-ellipsis">
      mahalanobis_distance
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<!--
SPDX-FileCopyrightText: 2024 Shell Global Solutions International B.V. All Rights Reserved.

SPDX-License-Identifier: Apache-2.0
-->

<h1 id="dlm">DLM</h1>


<div class="doc doc-object doc-module">



<a id="pyelq.dlm"></a>
    <div class="doc doc-contents first">

        <p>DLM module.</p>
<p>This module provides a class definition for the Dynamic Linear Models following Harrison and West
'Bayesian Forecasting and Dynamic Models' (2nd ed), Springer New York, NY, Chapter 4, https://doi.org/10.1007/b98971</p>









  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="pyelq.dlm.DLM" class="doc doc-heading">
            <code>DLM</code>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-dataclass"><code>dataclass</code></small>
  </span>

</h2>


    <div class="doc doc-contents ">


        <p>Defines the DLM in line with Harrison and West (2nd edition) Chapter 4.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="pyelq.dlm.DLM.f_matrix">f_matrix</span></code></td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>F matrix linking the state to the observables of
size [nof_state_parameters x nof_observables]</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="pyelq.dlm.DLM.g_matrix">g_matrix</span></code></td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>G matrix characterizing the state evolution of
size [nof_state_parameters x nof_state parameters]</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="pyelq.dlm.DLM.v_matrix">v_matrix</span></code></td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>V matrix being the covariance matrix of the zero mean observation noise
of size [nof_state_parameters x nof_observables]</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="pyelq.dlm.DLM.w_matrix">w_matrix</span></code></td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>W matrix being the covariance matrix of the zero mean system noise of
size [nof_state_parameters x nof_state parameters]</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="pyelq.dlm.DLM.g_power">g_power</span></code></td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Attribute to store G^k, does not get initialized</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>







              <details class="quote">
                <summary>Source code in <code>src/pyelq/dlm.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@dataclass</span>
<span class="k">class</span><span class="w"> </span><span class="nc">DLM</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Defines the DLM in line with Harrison and West (2nd edition) Chapter 4.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        f_matrix (np.ndarray, optional): F matrix linking the state to the observables of</span>
<span class="sd">            size [nof_state_parameters x nof_observables]</span>
<span class="sd">        g_matrix (np.ndarray, optional): G matrix characterizing the state evolution of</span>
<span class="sd">            size [nof_state_parameters x nof_state parameters]</span>
<span class="sd">        v_matrix (np.ndarray, optional): V matrix being the covariance matrix of the zero mean observation noise</span>
<span class="sd">            of size [nof_state_parameters x nof_observables]</span>
<span class="sd">        w_matrix (np.ndarray, optional): W matrix being the covariance matrix of the zero mean system noise of</span>
<span class="sd">            size [nof_state_parameters x nof_state parameters]</span>
<span class="sd">        g_power (np.ndarray, optional): Attribute to store G^k, does not get initialized</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">f_matrix</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">g_matrix</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">v_matrix</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">w_matrix</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">g_power</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">init</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">nof_observables</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Int: Number of observables as derived from the associated F matrix.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_matrix</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">f_matrix</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">return</span> <span class="mi">0</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">nof_state_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Int: Number of state parameters as derived from the associated G matrix.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">g_matrix</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">g_matrix</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">g_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="mi">0</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">calculate_g_power</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_power</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calculate the powers of the G matrix.</span>

<span class="sd">        Calculate the powers upfront, so we don&#39;t have to calculate it at every iteration. Result gets stored in the</span>
<span class="sd">        g_power attribute of the DLM class. We use an iterative way of calculating the power to have the fewest matrix</span>
<span class="sd">        multiplications necessary, i.e. we are not using numpy.linalg.matrix_power as that would leak to k factorial</span>
<span class="sd">        multiplications instead of the k we have now.</span>

<span class="sd">        Args:</span>
<span class="sd">            max_power (int): Maximum power to compute</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">nof_state_parameters</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">g_power</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">g_matrix</span> <span class="o">**</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="nb">range</span><span class="p">(</span><span class="n">max_power</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">g_power</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">nof_state_parameters</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nof_state_parameters</span><span class="p">,</span> <span class="n">max_power</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">g_power</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nof_state_parameters</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_power</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">g_power</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">g_power</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">g_matrix</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">polynomial_f_g</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nof_observables</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">order</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create F and G matrices associated with a polynomial DLM.</span>

<span class="sd">        Following Harrison and West (Chapter 7 on polynomial DLMs) with the exception that we use order==0 for a</span>
<span class="sd">        &quot;constant&quot; DLM and order==1 for linear growth DLM, order==2 for quadratic growth etc.</span>
<span class="sd">        Hence, the definition of n-th order polynomial DLM in Harrison &amp; West is implemented here with order=n-1</span>
<span class="sd">        We stack the observables in a block diagonal form. So the first #order of rows belong to the first observable,</span>
<span class="sd">        the second #order rows belong to the second observable etc.</span>
<span class="sd">        Results are being stored in the f_matrix and g_matrix attributes respectively</span>

<span class="sd">        Args:</span>
<span class="sd">            nof_observables (int): Dimension of observation</span>
<span class="sd">            order (int): Polynomial order (0=constant, 1=linear, 2=quadratic etc.)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">e_n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">order</span><span class="p">))[:,</span> <span class="kc">None</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">kron</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">nof_observables</span><span class="p">),</span> <span class="n">e_n</span><span class="p">)</span>

        <span class="n">l_n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">g_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">kron</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">nof_observables</span><span class="p">),</span> <span class="n">l_n</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">simulate_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">init_state</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">nof_timesteps</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Simulate data from DLM model.</span>

<span class="sd">        Function to simulate state evolution and corresponding observations according to model as specified through DLM</span>
<span class="sd">        class attributes (F, G, V and W matrices)</span>

<span class="sd">        Args:</span>
<span class="sd">            init_state (np.ndarray): Initial state vector to start simulating from of size [nof_state_parameters x 1]</span>
<span class="sd">            nof_timesteps (int): Number of timesteps to simulate</span>

<span class="sd">        Returns:</span>
<span class="sd">            state (np.ndarray): Simulated state vectors of size [nof_state_parameters x nof_timesteps]</span>
<span class="sd">            obs (np.ndarray): Simulated observations of size [nof_observables x nof_timesteps]</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_matrix</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">g_matrix</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_matrix</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_matrix</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Please specify all matrices (F, G, V and W)&quot;</span><span class="p">)</span>

        <span class="n">obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">nof_observables</span><span class="p">,</span> <span class="n">nof_timesteps</span><span class="p">))</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">nof_state_parameters</span><span class="p">,</span> <span class="n">nof_timesteps</span><span class="p">))</span>

        <span class="n">state</span><span class="p">[:,</span> <span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">init_state</span>
        <span class="n">mean_state_noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nof_state_parameters</span><span class="p">)</span>
        <span class="n">mean_observation_noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nof_observables</span><span class="p">)</span>

        <span class="n">random_generator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nof_timesteps</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">state</span><span class="p">[:,</span> <span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">g_matrix</span> <span class="o">@</span> <span class="n">init_state</span>
                    <span class="o">+</span> <span class="n">random_generator</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean_state_noise</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_matrix</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">state</span><span class="p">[:,</span> <span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">g_matrix</span> <span class="o">@</span> <span class="n">state</span><span class="p">[:,</span> <span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]]</span>
                    <span class="o">+</span> <span class="n">random_generator</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean_state_noise</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_matrix</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
                <span class="p">)</span>
            <span class="n">obs</span><span class="p">[:,</span> <span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">f_matrix</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">state</span><span class="p">[:,</span> <span class="p">[</span><span class="n">i</span><span class="p">]]</span>
                <span class="o">+</span> <span class="n">random_generator</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean_observation_noise</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_matrix</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">state</span><span class="p">,</span> <span class="n">obs</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forecast_mean</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">current_mean_state</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">forecast_steps</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Perform forecasting of the state and observation mean parameters.</span>

<span class="sd">        Following Harrison and West (2nd ed) Chapter 4.4 (Forecast Distributions), corollary 4.1, assuming F and G are</span>
<span class="sd">        constant over time.</span>
<span class="sd">        Note that in the output the second axis of the output arrays is the forecast dimension consistent with the</span>
<span class="sd">        forecast steps input, all forecast steps contained in the forecast steps argument are returned.</span>

<span class="sd">        Args:</span>
<span class="sd">            current_mean_state (np.ndarray): Current mean parameter for the state of size [nof_state_parameters x 1]</span>
<span class="sd">            forecast_steps (Union[int, list, np.ndarray], optional): Steps ahead to forecast</span>

<span class="sd">        Returns:</span>
<span class="sd">            a_t_k (np.array): Forecast values of state mean parameter of the size</span>
<span class="sd">                [nof_observables x size(forecast_steps)]</span>
<span class="sd">            f_t_k (np.array): Forecast values of observation mean parameter of the size</span>
<span class="sd">                [nof_observables x size(forecast_steps)]</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">min_forecast</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">amin</span><span class="p">(</span><span class="n">forecast_steps</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">min_forecast</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Minimum forecast should be &gt;= 1, currently it is </span><span class="si">{</span><span class="n">min_forecast</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">forecast_steps</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">forecast_steps</span> <span class="o">=</span> <span class="p">[</span><span class="n">forecast_steps</span><span class="p">]</span>

        <span class="n">a_t_k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">g_power</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">step</span><span class="p">]</span> <span class="o">@</span> <span class="n">current_mean_state</span> <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">forecast_steps</span><span class="p">])</span>
        <span class="n">f_t_k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_matrix</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">a_t_k</span>

        <span class="k">return</span> <span class="n">a_t_k</span><span class="p">,</span> <span class="n">f_t_k</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forecast_covariance</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">c_matrix</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">forecast_steps</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Perform forecasting of the state and observation covariance parameters.</span>

<span class="sd">        Following Harrison and West (2nd ed) Chapter 4.4 (Forecast Distributions), assuming F, G, V and W are</span>
<span class="sd">        constant over time.</span>
<span class="sd">        Note that in the output the third axis of the output arrays is the forecast dimension consistent with the</span>
<span class="sd">        forecast steps input, all forecast steps contained in the forecast steps argument are returned.</span>
<span class="sd">        sum_g_w_g is initialized as G^k @ W @ G^k for k==0, hence we initialize as W</span>
<span class="sd">        Because of zero based indexing, in the for loop i==1 means 2-step ahead forecast which requires element</span>
<span class="sd">        (i+1) of the g_power attribute as the third dimension serves as the actual power of the G matrix</span>

<span class="sd">        Args:</span>
<span class="sd">            c_matrix (np.ndarray): Current posterior covariance estimate for the state of size</span>
<span class="sd">                [nof_state_parameters x nof_state_parameters]</span>
<span class="sd">            forecast_steps (Union[int, list, np.ndarray], optional): Steps ahead to forecast</span>

<span class="sd">        Returns:</span>
<span class="sd">            r_t_k (np.array): Forecast values of estimated prior state covariance of the size</span>
<span class="sd">                [nof_state_parameters x nof_state_parameters x size(forecast_steps)]</span>
<span class="sd">            q_t_k (np.array): Forecast values of estimated observation covariance of the size</span>
<span class="sd">                [nof_observables x nof_observables x size(forecast_steps)]</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">min_forecast</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">amin</span><span class="p">(</span><span class="n">forecast_steps</span><span class="p">)</span>
        <span class="n">max_forecast</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="n">forecast_steps</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">min_forecast</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Minimum forecast should be &gt;= 1, currently it is </span><span class="si">{</span><span class="n">min_forecast</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">forecast_steps</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">forecast_steps</span> <span class="o">=</span> <span class="p">[</span><span class="n">forecast_steps</span><span class="p">]</span>

        <span class="n">sum_g_w_g</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">nof_state_parameters</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nof_state_parameters</span><span class="p">,</span> <span class="n">max_forecast</span><span class="p">))</span>
        <span class="n">sum_g_w_g</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_matrix</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_forecast</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">sum_g_w_g</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">sum_g_w_g</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">g_power</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_matrix</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">g_power</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">T</span>
            <span class="p">)</span>

        <span class="n">r_t_k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dstack</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">g_power</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">step</span><span class="p">]</span> <span class="o">@</span> <span class="n">c_matrix</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">g_power</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">step</span><span class="p">]</span><span class="o">.</span><span class="n">T</span> <span class="o">+</span> <span class="n">sum_g_w_g</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">step</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">forecast_steps</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="n">q_t_k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dstack</span><span class="p">(</span>
            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">f_matrix</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">r_t_k</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">idx</span><span class="p">]</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_matrix</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_matrix</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">r_t_k</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])]</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">r_t_k</span><span class="p">,</span> <span class="n">q_t_k</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">update_posterior</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">a_t</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">r_matrix_t</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">q_matrix_t</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">error</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Update of the posterior mean and covariance of the state.</span>

<span class="sd">        Following Harrison and West (2nd ed) Chapter 4.4 (Forecast Distributions), assuming F, G, V and W are</span>
<span class="sd">        constant over time.</span>
<span class="sd">        We are using a solver instead of calculating the inverse of Q directly</span>
<span class="sd">        Setting inf values in Q equal to 0 after the solver function for computational issues, otherwise we would</span>
<span class="sd">        get 0 * inf = nan, where we want the result to be 0.</span>

<span class="sd">        Args:</span>
<span class="sd">            a_t (np.ndarray): Current prior mean of the state of size [nof_state_parameters x 1]</span>
<span class="sd">            r_matrix_t (np.ndarray): Current prior covariance of the state of size [nof_state_parameters x nof_state_parameters]</span>
<span class="sd">            q_matrix_t (np.ndarray): Current one step ahead forecast covariance estimate of the observations of size [nof_observables x nof_observables]</span>
<span class="sd">            error (np.ndarray): Error associated with the one step ahead forecast (observation - forecast) of size [nof_observables x 1]</span>

<span class="sd">        Returns:</span>
<span class="sd">            m_t (np.array): Posterior mean estimate of the state of size [nof_state_parameters x 1]</span>
<span class="sd">            c_matrix (np.array): Posterior covariance estimate of the state of size [nof_state_parameters x nof_state_parameters]</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">nof_state_parameters</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">a_matrix_t</span> <span class="o">=</span> <span class="n">r_matrix_t</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_matrix</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">q_matrix_t</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">a_matrix_t</span> <span class="o">=</span> <span class="n">r_matrix_t</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">q_matrix_t</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_matrix</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
        <span class="n">m_t</span> <span class="o">=</span> <span class="n">a_t</span> <span class="o">+</span> <span class="n">a_matrix_t</span> <span class="o">@</span> <span class="n">error</span>
        <span class="n">q_matrix_t</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">q_matrix_t</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">c_matrix</span> <span class="o">=</span> <span class="n">r_matrix_t</span> <span class="o">-</span> <span class="n">a_matrix_t</span> <span class="o">@</span> <span class="n">q_matrix_t</span> <span class="o">@</span> <span class="n">a_matrix_t</span><span class="o">.</span><span class="n">T</span>

        <span class="k">return</span> <span class="n">m_t</span><span class="p">,</span> <span class="n">c_matrix</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">dlm_full_update</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">new_observation</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">current_mean_state</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">current_cov_state</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;learn&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Perform 1 step of the full DLM update.</span>

<span class="sd">        Following Harrison and West (2nd ed) we perform all steps to update the entire DLM model and obtain new</span>
<span class="sd">        estimates for all parameters involved, including nan value handling.</span>
<span class="sd">        When mode == &#39;learn&#39; the parameters are updated, when mode == &#39;ignore&#39; the current observation is ignored and</span>
<span class="sd">        the posterior is set equal to the prior</span>
<span class="sd">        When no observation is present (i.e. a nan value) we let the covariance (V matrix) for that particular sensor</span>
<span class="sd">        such that we set the variance of that sensor for that time instance to infinity and set all cross (covariance)</span>
<span class="sd">        terms to 0. Instead of changing this in the V matrix, we simply adjust the Q matrix accordingly. Effectively,</span>
<span class="sd">        we set the posterior equal to the prior for that particular sensor and the uncertainty associated with the new</span>
<span class="sd">        forecast gets increased. We set the error equal to zero for computational issues, first but finally set it equal</span>
<span class="sd">        to nan in the end.</span>

<span class="sd">        Args:</span>
<span class="sd">            new_observation (np.ndarray): New observations to use in the updating of the estimates of size [nof_observables x 1]</span>
<span class="sd">            current_mean_state (np.ndarray):  Current mean estimate for the state of size [nof_state_parameters x 1]</span>
<span class="sd">            current_cov_state (np.ndarray):  Current covariance estimate for the state of size [nof_state_parameters x nof_state_parameters]</span>
<span class="sd">            mode (str, optional): String indicating whether the DLM needs to be updated using the new observation or not. Currently, `learn` and `ignore` are implemented</span>

<span class="sd">        Returns:</span>
<span class="sd">            new_mean_state (np.ndarray): New mean estimate for the state of size [nof_state_parameters x 1]</span>
<span class="sd">            new_cov_state (np.ndarray): New covariance estimate for the state of size [nof_state_parameters x nof_state_parameters]</span>
<span class="sd">            error (np.ndarray): Error between the observation and the forecast (observation - forecast) of size [nof_observables x 1]</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">a_t</span><span class="p">,</span> <span class="n">f_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forecast_mean</span><span class="p">(</span><span class="n">current_mean_state</span><span class="p">,</span> <span class="n">forecast_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">r_matrix_t</span><span class="p">,</span> <span class="n">q_matrix_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forecast_covariance</span><span class="p">(</span><span class="n">current_cov_state</span><span class="p">,</span> <span class="n">forecast_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">error</span> <span class="o">=</span> <span class="n">new_observation</span> <span class="o">-</span> <span class="n">f_t</span>

        <span class="n">nan_bool</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">new_observation</span><span class="p">)</span>
        <span class="n">nan_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="n">nan_bool</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">nan_bool</span><span class="p">):</span>
            <span class="n">q_matrix_t</span><span class="p">[</span><span class="n">nan_idx</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_matrix</span><span class="p">[</span><span class="n">nan_idx</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">q_matrix_t</span><span class="p">[:,</span> <span class="n">nan_idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_matrix</span><span class="p">[:,</span> <span class="n">nan_idx</span><span class="p">]</span>
            <span class="n">q_matrix_t</span><span class="p">[</span><span class="n">nan_idx</span><span class="p">,</span> <span class="n">nan_idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
            <span class="n">error</span><span class="p">[</span><span class="n">nan_idx</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;learn&quot;</span><span class="p">:</span>
            <span class="n">new_mean_state</span><span class="p">,</span> <span class="n">new_cov_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_posterior</span><span class="p">(</span><span class="n">a_t</span><span class="p">,</span> <span class="n">r_matrix_t</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">q_matrix_t</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">error</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;ignore&quot;</span><span class="p">:</span>
            <span class="n">new_mean_state</span> <span class="o">=</span> <span class="n">a_t</span>
            <span class="n">new_cov_state</span> <span class="o">=</span> <span class="n">r_matrix_t</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mode </span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s2"> not implemented&quot;</span><span class="p">)</span>

        <span class="n">error</span><span class="p">[</span><span class="n">nan_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

        <span class="k">return</span> <span class="n">new_mean_state</span><span class="p">,</span> <span class="n">new_cov_state</span><span class="p">,</span> <span class="n">error</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">calculate_mahalanobis_distance</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">new_observations</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">current_mean_state</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">current_cov_state</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">forecast_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">return_statistics</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calculate the mahalanobis distance.</span>

<span class="sd">        Calculating the Mahalanobis distance which is defined as error.T @ covariance^(-1) @ error</span>
<span class="sd">        The error is flatted in row-major (C-style) This returns the stacked rows, which in our case is the errors per</span>
<span class="sd">        observation parameter stacked and this is exactly what we want: array([[1, 2], [3, 4]]).reshape((-1, 1),</span>
<span class="sd">        order=&#39;C&#39;) becomes column array([1, 2 3, 4])</span>
<span class="sd">        Using a solve method instead of calculating inverse matrices directly</span>
<span class="sd">        When calculating mhd_per_obs_param we use the partial result and reshape the temporary output such that we can</span>
<span class="sd">        sum the correct elements associated with the same observable together</span>
<span class="sd">        When no observation is present (i.e. a nan value) we let the covariance (V matrix) for that particular sensor</span>
<span class="sd">        such that we set the variance of that sensor for that time instance to infinity and set all cross (covariance)</span>
<span class="sd">        terms to 0. Instead of changing this in the V matrix, we simply adjust the Q matrix accordingly. Effectively,</span>
<span class="sd">        we set the posterior equal to the prior for that particular sensor and the uncertainty associated with the new</span>
<span class="sd">        forecast gets increased. We set the error equal to zero for computational issues, but this does decrease the</span>
<span class="sd">        number of degrees of freedom for that particular Mahalanobis distance calculation, basically decreasing the</span>
<span class="sd">        Mahalanobis distance. We allow the option to output the number of degrees of freedom and chi2 statistic which</span>
<span class="sd">        allows to take this decrease in degrees of freedom into account.</span>

<span class="sd">        Args:</span>
<span class="sd">            new_observations (np.ndarray): New observations to use in the calculation of the mahalanobis distance of</span>
<span class="sd">                size [nof_observables x forecast_steps]</span>
<span class="sd">            current_mean_state (np.ndarray): Current mean estimate for the state of size [nof_state_parameters x 1]</span>
<span class="sd">            current_cov_state (np.ndarray): Current covariance estimate for the state of size</span>
<span class="sd">                [nof_state_parameters x nof_state_parameters]</span>
<span class="sd">            forecast_steps (int, optional): Number of steps ahead to forecast and use in the mahalanobis distance</span>
<span class="sd">                calculation</span>
<span class="sd">            return_statistics (bool, optional): Boolean to return used degrees of freedom and chi2 statistic</span>
<span class="sd">        Returns:</span>
<span class="sd">            mhd_overall (float): mahalanobis distance over all observables</span>
<span class="sd">            mhd_per_obs_param (np.ndarray): mahalanobis distance per observation parameter of size [nof_observables, 1]</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">forecast_steps</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s2">&quot;Forecast steps should be a positive integer&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">new_observations</span><span class="o">.</span><span class="n">size</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nof_observables</span> <span class="o">!=</span> <span class="n">forecast_steps</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s2">&quot;Sizes of new observations and forecast steps are not aligning&quot;</span><span class="p">)</span>

        <span class="n">_</span><span class="p">,</span> <span class="n">f_t_k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forecast_mean</span><span class="p">(</span><span class="n">current_mean_state</span><span class="p">,</span> <span class="n">forecast_steps</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">forecast_steps</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">new_observations</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">f_t_k</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s2">&quot;Dimensions of new_observations are not aligning with dimensions of forecast&quot;</span><span class="p">)</span>

        <span class="n">error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">new_observations</span><span class="p">,</span> <span class="n">f_t_k</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">)</span>

        <span class="n">r_t_k</span><span class="p">,</span> <span class="n">q_t_k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forecast_covariance</span><span class="p">(</span><span class="n">current_cov_state</span><span class="p">,</span> <span class="n">forecast_steps</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">forecast_steps</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">nan_bool</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">new_observations</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">nan_bool</span><span class="p">):</span>
            <span class="n">nan_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="n">nan_bool</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">nan_idx</span><span class="p">:</span>
                <span class="n">q_t_k</span><span class="p">[</span><span class="n">value</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">:,</span> <span class="n">value</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_matrix</span><span class="p">[</span><span class="n">value</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">:]</span>
                <span class="n">q_t_k</span><span class="p">[:,</span> <span class="n">value</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">value</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_matrix</span><span class="p">[:,</span> <span class="n">value</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>

            <span class="n">q_t_k</span><span class="p">[</span><span class="n">nan_idx</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">nan_idx</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">nan_idx</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
            <span class="n">error</span><span class="p">[</span><span class="n">nan_bool</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">if</span> <span class="n">forecast_steps</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">full_covariance</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_full_covariance</span><span class="p">(</span><span class="n">r_t_k</span><span class="o">=</span><span class="n">r_t_k</span><span class="p">,</span> <span class="n">q_t_k</span><span class="o">=</span><span class="n">q_t_k</span><span class="p">,</span> <span class="n">forecast_steps</span><span class="o">=</span><span class="n">forecast_steps</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">full_covariance</span> <span class="o">=</span> <span class="n">q_t_k</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span>

        <span class="n">mhd_overall</span> <span class="o">=</span> <span class="n">mahalanobis_distance</span><span class="p">(</span><span class="n">error</span><span class="o">=</span><span class="n">error</span><span class="p">,</span> <span class="n">cov_matrix</span><span class="o">=</span><span class="n">full_covariance</span><span class="p">)</span>
        <span class="n">mhd_per_obs_param</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">nof_observables</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

        <span class="k">for</span> <span class="n">i_obs</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nof_observables</span><span class="p">):</span>
            <span class="n">ind_hrz</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">forecast_steps</span><span class="p">))</span> <span class="o">+</span> <span class="n">i_obs</span> <span class="o">*</span> <span class="n">forecast_steps</span>
            <span class="n">mhd_per_obs_param</span><span class="p">[</span><span class="n">i_obs</span><span class="p">]</span> <span class="o">=</span> <span class="n">mahalanobis_distance</span><span class="p">(</span>
                <span class="n">error</span><span class="o">=</span><span class="n">error</span><span class="p">[</span><span class="n">ind_hrz</span><span class="p">],</span> <span class="n">cov_matrix</span><span class="o">=</span><span class="n">full_covariance</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ix_</span><span class="p">(</span><span class="n">ind_hrz</span><span class="p">,</span> <span class="n">ind_hrz</span><span class="p">)]</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">nof_observables</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">mhd_per_obs_param</span> <span class="o">=</span> <span class="n">mhd_per_obs_param</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">return_statistics</span><span class="p">:</span>
            <span class="n">dof_per_obs_param</span> <span class="o">=</span> <span class="p">(</span><span class="n">nan_bool</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">nan_bool</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">nof_observables</span><span class="p">,</span> <span class="mi">1</span>
            <span class="p">)</span>
            <span class="n">dof_overall</span> <span class="o">=</span> <span class="n">dof_per_obs_param</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
            <span class="n">chi2_cdf_per_obs_param</span> <span class="o">=</span> <span class="n">chi2</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">mhd_per_obs_param</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">dof_per_obs_param</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">nof_observables</span><span class="p">,</span> <span class="mi">1</span>
            <span class="p">)</span>
            <span class="n">chi2_cdf_overall</span> <span class="o">=</span> <span class="n">chi2</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">mhd_overall</span><span class="p">,</span> <span class="n">dof_overall</span><span class="p">)</span>

            <span class="k">return</span> <span class="p">(</span>
                <span class="n">mhd_overall</span><span class="p">,</span>
                <span class="n">mhd_per_obs_param</span><span class="p">,</span>
                <span class="n">dof_overall</span><span class="p">,</span>
                <span class="n">dof_per_obs_param</span><span class="p">,</span>
                <span class="n">chi2_cdf_overall</span><span class="p">,</span>
                <span class="n">chi2_cdf_per_obs_param</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">mhd_overall</span><span class="p">,</span> <span class="n">mhd_per_obs_param</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">create_full_covariance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">r_t_k</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">q_t_k</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">forecast_steps</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Helper function to construct the full covariance matrix.</span>

<span class="sd">        Following Harrison and West (2nd ed) Chapter 4.4 (Forecast distributions) Theorem 4.2 and corollary 4.2</span>
<span class="sd">        we construct the full covariance matrix. This full covariance matrix is the covariance matrix of all forecasted</span>
<span class="sd">        observations with respect to each other. Hence, it&#39;s COV[Y_{t+k}, Y_{t+j}] with j and k 1&lt;=j,k&lt;=forecast steps</span>
<span class="sd">        input argument and Y_{t+k} the k step ahead forecast of the observation at time t</span>

<span class="sd">        The matrix is build up using the different blocks for different covariances between observations i and j.</span>
<span class="sd">        The diagonals of each block are calculated first as q_t_k[i, j, :].</span>
<span class="sd">        Next the i, j-th (lower triangular) entry of the m, n-th block is calculated as</span>
<span class="sd">        (F.T @ G^(i-j) r_t_k[:, :, j] @ F)[i, j]</span>
<span class="sd">        Next each upper triangular part of each lower diagonal block is calculated and next the entire upper triangular</span>
<span class="sd">        part of the full matrix is calculated</span>

<span class="sd">        Args:</span>
<span class="sd">            r_t_k (np.array): Forecast values of estimated prior state covariance of the size</span>
<span class="sd">                [nof_state_parameters x nof_state_parameters x forecast_steps]</span>
<span class="sd">            q_t_k (np.array): Forecast values of estimated observation covariance of the size</span>
<span class="sd">                [nof_observables x nof_observables x forecast_steps]</span>
<span class="sd">            forecast_steps (int): Maximum number of steps ahead to forecast and use all of those in the mahalanobis</span>
<span class="sd">                distance calculation</span>

<span class="sd">        Returns:</span>
<span class="sd">            full_covariance (np.array): Full covariance matrix of all forecasted observations with respect to each other</span>
<span class="sd">            having size [(nof_observables * forecast_steps) X (nof_observables * forecast_steps)]</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">full_covariance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">forecast_steps</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">nof_observables</span><span class="p">,</span> <span class="n">forecast_steps</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">nof_observables</span><span class="p">))</span>
        <span class="n">base_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">forecast_steps</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">block_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nof_observables</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">block_j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">block_i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
                <span class="n">block_rows</span> <span class="o">=</span> <span class="n">base_idx</span> <span class="o">+</span> <span class="n">block_i</span> <span class="o">*</span> <span class="n">forecast_steps</span>
                <span class="n">block_cols</span> <span class="o">=</span> <span class="n">base_idx</span> <span class="o">+</span> <span class="n">block_j</span> <span class="o">*</span> <span class="n">forecast_steps</span>
                <span class="n">full_covariance</span><span class="p">[</span><span class="n">block_rows</span><span class="p">,</span> <span class="n">block_cols</span><span class="p">]</span> <span class="o">=</span> <span class="n">q_t_k</span><span class="p">[</span><span class="n">block_i</span><span class="p">,</span> <span class="n">block_j</span><span class="p">,</span> <span class="p">:]</span>

        <span class="n">temp_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nof_observables</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">sub_i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stop</span><span class="o">=</span><span class="n">forecast_steps</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">sub_row</span> <span class="o">=</span> <span class="n">temp_idx</span> <span class="o">*</span> <span class="n">forecast_steps</span> <span class="o">+</span> <span class="n">sub_i</span>
            <span class="k">for</span> <span class="n">sub_j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">sub_i</span><span class="p">):</span>
                <span class="n">sub_col</span> <span class="o">=</span> <span class="n">temp_idx</span> <span class="o">*</span> <span class="n">forecast_steps</span> <span class="o">+</span> <span class="n">sub_j</span>
                <span class="n">sub_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ix_</span><span class="p">(</span><span class="n">sub_row</span><span class="p">,</span> <span class="n">sub_col</span><span class="p">)</span>
                <span class="n">full_covariance</span><span class="p">[</span><span class="n">sub_idx</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">f_matrix</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">g_power</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">sub_i</span> <span class="o">-</span> <span class="n">sub_j</span><span class="p">]</span> <span class="o">@</span> <span class="n">r_t_k</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">sub_j</span><span class="p">]</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_matrix</span>
                <span class="p">)</span>

        <span class="k">for</span> <span class="n">block_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nof_observables</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">block_j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">block_i</span><span class="p">):</span>
                <span class="n">block_rows</span> <span class="o">=</span> <span class="n">base_idx</span> <span class="o">+</span> <span class="n">block_i</span> <span class="o">*</span> <span class="n">forecast_steps</span>
                <span class="n">block_cols</span> <span class="o">=</span> <span class="n">base_idx</span> <span class="o">+</span> <span class="n">block_j</span> <span class="o">*</span> <span class="n">forecast_steps</span>
                <span class="n">block_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ix_</span><span class="p">(</span><span class="n">block_rows</span><span class="p">,</span> <span class="n">block_cols</span><span class="p">)</span>
                <span class="n">full_covariance</span><span class="p">[</span><span class="n">block_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">full_covariance</span><span class="p">[</span><span class="n">block_idx</span><span class="p">]</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="n">full_covariance</span><span class="p">[</span><span class="n">block_idx</span><span class="p">],</span> <span class="n">k</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>

        <span class="n">full_covariance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="n">full_covariance</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="n">full_covariance</span><span class="p">,</span> <span class="n">k</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>

        <span class="k">return</span> <span class="n">full_covariance</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="pyelq.dlm.DLM.nof_observables" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">nof_observables</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h3>


    <div class="doc doc-contents ">

        

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="pyelq.dlm.DLM.nof_state_parameters" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">nof_state_parameters</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h3>


    <div class="doc doc-contents ">

        

    </div>

</div>



<div class="doc doc-object doc-function">


<h3 id="pyelq.dlm.DLM.calculate_g_power" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">calculate_g_power</span><span class="p">(</span><span class="n">max_power</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Calculate the powers of the G matrix.</p>
<p>Calculate the powers upfront, so we don't have to calculate it at every iteration. Result gets stored in the
g_power attribute of the DLM class. We use an iterative way of calculating the power to have the fewest matrix
multiplications necessary, i.e. we are not using numpy.linalg.matrix_power as that would leak to k factorial
multiplications instead of the k we have now.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>max_power</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Maximum power to compute</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>src/pyelq/dlm.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_g_power</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_power</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Calculate the powers of the G matrix.</span>

<span class="sd">    Calculate the powers upfront, so we don&#39;t have to calculate it at every iteration. Result gets stored in the</span>
<span class="sd">    g_power attribute of the DLM class. We use an iterative way of calculating the power to have the fewest matrix</span>
<span class="sd">    multiplications necessary, i.e. we are not using numpy.linalg.matrix_power as that would leak to k factorial</span>
<span class="sd">    multiplications instead of the k we have now.</span>

<span class="sd">    Args:</span>
<span class="sd">        max_power (int): Maximum power to compute</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">nof_state_parameters</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">g_power</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">g_matrix</span> <span class="o">**</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="nb">range</span><span class="p">(</span><span class="n">max_power</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">g_power</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">nof_state_parameters</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nof_state_parameters</span><span class="p">,</span> <span class="n">max_power</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">g_power</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nof_state_parameters</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_power</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">g_power</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">g_power</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">g_matrix</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="pyelq.dlm.DLM.polynomial_f_g" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">polynomial_f_g</span><span class="p">(</span><span class="n">nof_observables</span><span class="p">,</span> <span class="n">order</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Create F and G matrices associated with a polynomial DLM.</p>
<p>Following Harrison and West (Chapter 7 on polynomial DLMs) with the exception that we use order==0 for a
"constant" DLM and order==1 for linear growth DLM, order==2 for quadratic growth etc.
Hence, the definition of n-th order polynomial DLM in Harrison &amp; West is implemented here with order=n-1
We stack the observables in a block diagonal form. So the first #order of rows belong to the first observable,
the second #order rows belong to the second observable etc.
Results are being stored in the f_matrix and g_matrix attributes respectively</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>nof_observables</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dimension of observation</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>order</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Polynomial order (0=constant, 1=linear, 2=quadratic etc.)</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>src/pyelq/dlm.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span>
<span class="normal">90</span>
<span class="normal">91</span>
<span class="normal">92</span>
<span class="normal">93</span>
<span class="normal">94</span>
<span class="normal">95</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">polynomial_f_g</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nof_observables</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">order</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Create F and G matrices associated with a polynomial DLM.</span>

<span class="sd">    Following Harrison and West (Chapter 7 on polynomial DLMs) with the exception that we use order==0 for a</span>
<span class="sd">    &quot;constant&quot; DLM and order==1 for linear growth DLM, order==2 for quadratic growth etc.</span>
<span class="sd">    Hence, the definition of n-th order polynomial DLM in Harrison &amp; West is implemented here with order=n-1</span>
<span class="sd">    We stack the observables in a block diagonal form. So the first #order of rows belong to the first observable,</span>
<span class="sd">    the second #order rows belong to the second observable etc.</span>
<span class="sd">    Results are being stored in the f_matrix and g_matrix attributes respectively</span>

<span class="sd">    Args:</span>
<span class="sd">        nof_observables (int): Dimension of observation</span>
<span class="sd">        order (int): Polynomial order (0=constant, 1=linear, 2=quadratic etc.)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">e_n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">order</span><span class="p">))[:,</span> <span class="kc">None</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">f_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">kron</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">nof_observables</span><span class="p">),</span> <span class="n">e_n</span><span class="p">)</span>

    <span class="n">l_n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">g_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">kron</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">nof_observables</span><span class="p">),</span> <span class="n">l_n</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="pyelq.dlm.DLM.simulate_data" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">simulate_data</span><span class="p">(</span><span class="n">init_state</span><span class="p">,</span> <span class="n">nof_timesteps</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Simulate data from DLM model.</p>
<p>Function to simulate state evolution and corresponding observations according to model as specified through DLM
class attributes (F, G, V and W matrices)</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>init_state</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Initial state vector to start simulating from of size [nof_state_parameters x 1]</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>nof_timesteps</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of timesteps to simulate</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>state</code></td>            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Simulated state vectors of size [nof_state_parameters x nof_timesteps]</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
<td><code>obs</code></td>            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Simulated observations of size [nof_observables x nof_timesteps]</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>src/pyelq/dlm.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">simulate_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">init_state</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">nof_timesteps</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Simulate data from DLM model.</span>

<span class="sd">    Function to simulate state evolution and corresponding observations according to model as specified through DLM</span>
<span class="sd">    class attributes (F, G, V and W matrices)</span>

<span class="sd">    Args:</span>
<span class="sd">        init_state (np.ndarray): Initial state vector to start simulating from of size [nof_state_parameters x 1]</span>
<span class="sd">        nof_timesteps (int): Number of timesteps to simulate</span>

<span class="sd">    Returns:</span>
<span class="sd">        state (np.ndarray): Simulated state vectors of size [nof_state_parameters x nof_timesteps]</span>
<span class="sd">        obs (np.ndarray): Simulated observations of size [nof_observables x nof_timesteps]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_matrix</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">g_matrix</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_matrix</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_matrix</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Please specify all matrices (F, G, V and W)&quot;</span><span class="p">)</span>

    <span class="n">obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">nof_observables</span><span class="p">,</span> <span class="n">nof_timesteps</span><span class="p">))</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">nof_state_parameters</span><span class="p">,</span> <span class="n">nof_timesteps</span><span class="p">))</span>

    <span class="n">state</span><span class="p">[:,</span> <span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">init_state</span>
    <span class="n">mean_state_noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nof_state_parameters</span><span class="p">)</span>
    <span class="n">mean_observation_noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nof_observables</span><span class="p">)</span>

    <span class="n">random_generator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nof_timesteps</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">state</span><span class="p">[:,</span> <span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">g_matrix</span> <span class="o">@</span> <span class="n">init_state</span>
                <span class="o">+</span> <span class="n">random_generator</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean_state_noise</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_matrix</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">state</span><span class="p">[:,</span> <span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">g_matrix</span> <span class="o">@</span> <span class="n">state</span><span class="p">[:,</span> <span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]]</span>
                <span class="o">+</span> <span class="n">random_generator</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean_state_noise</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_matrix</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
            <span class="p">)</span>
        <span class="n">obs</span><span class="p">[:,</span> <span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">f_matrix</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">state</span><span class="p">[:,</span> <span class="p">[</span><span class="n">i</span><span class="p">]]</span>
            <span class="o">+</span> <span class="n">random_generator</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean_observation_noise</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_matrix</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">state</span><span class="p">,</span> <span class="n">obs</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="pyelq.dlm.DLM.forecast_mean" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forecast_mean</span><span class="p">(</span><span class="n">current_mean_state</span><span class="p">,</span> <span class="n">forecast_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Perform forecasting of the state and observation mean parameters.</p>
<p>Following Harrison and West (2nd ed) Chapter 4.4 (Forecast Distributions), corollary 4.1, assuming F and G are
constant over time.
Note that in the output the second axis of the output arrays is the forecast dimension consistent with the
forecast steps input, all forecast steps contained in the forecast steps argument are returned.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>current_mean_state</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Current mean parameter for the state of size [nof_state_parameters x 1]</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>forecast_steps</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="int">int</span>, <span title="list">list</span>, <span title="numpy.ndarray">ndarray</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Steps ahead to forecast</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>a_t_k</code></td>            <td>
                  <code><span title="numpy.array">array</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Forecast values of state mean parameter of the size
[nof_observables x size(forecast_steps)]</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
<td><code>f_t_k</code></td>            <td>
                  <code><span title="numpy.array">array</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Forecast values of observation mean parameter of the size
[nof_observables x size(forecast_steps)]</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>src/pyelq/dlm.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">forecast_mean</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">current_mean_state</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">forecast_steps</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Perform forecasting of the state and observation mean parameters.</span>

<span class="sd">    Following Harrison and West (2nd ed) Chapter 4.4 (Forecast Distributions), corollary 4.1, assuming F and G are</span>
<span class="sd">    constant over time.</span>
<span class="sd">    Note that in the output the second axis of the output arrays is the forecast dimension consistent with the</span>
<span class="sd">    forecast steps input, all forecast steps contained in the forecast steps argument are returned.</span>

<span class="sd">    Args:</span>
<span class="sd">        current_mean_state (np.ndarray): Current mean parameter for the state of size [nof_state_parameters x 1]</span>
<span class="sd">        forecast_steps (Union[int, list, np.ndarray], optional): Steps ahead to forecast</span>

<span class="sd">    Returns:</span>
<span class="sd">        a_t_k (np.array): Forecast values of state mean parameter of the size</span>
<span class="sd">            [nof_observables x size(forecast_steps)]</span>
<span class="sd">        f_t_k (np.array): Forecast values of observation mean parameter of the size</span>
<span class="sd">            [nof_observables x size(forecast_steps)]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">min_forecast</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">amin</span><span class="p">(</span><span class="n">forecast_steps</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">min_forecast</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Minimum forecast should be &gt;= 1, currently it is </span><span class="si">{</span><span class="n">min_forecast</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">forecast_steps</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">forecast_steps</span> <span class="o">=</span> <span class="p">[</span><span class="n">forecast_steps</span><span class="p">]</span>

    <span class="n">a_t_k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">g_power</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">step</span><span class="p">]</span> <span class="o">@</span> <span class="n">current_mean_state</span> <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">forecast_steps</span><span class="p">])</span>
    <span class="n">f_t_k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_matrix</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">a_t_k</span>

    <span class="k">return</span> <span class="n">a_t_k</span><span class="p">,</span> <span class="n">f_t_k</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="pyelq.dlm.DLM.forecast_covariance" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forecast_covariance</span><span class="p">(</span><span class="n">c_matrix</span><span class="p">,</span> <span class="n">forecast_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Perform forecasting of the state and observation covariance parameters.</p>
<p>Following Harrison and West (2nd ed) Chapter 4.4 (Forecast Distributions), assuming F, G, V and W are
constant over time.
Note that in the output the third axis of the output arrays is the forecast dimension consistent with the
forecast steps input, all forecast steps contained in the forecast steps argument are returned.
sum_g_w_g is initialized as G^k @ W @ G^k for k==0, hence we initialize as W
Because of zero based indexing, in the for loop i==1 means 2-step ahead forecast which requires element
(i+1) of the g_power attribute as the third dimension serves as the actual power of the G matrix</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>c_matrix</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Current posterior covariance estimate for the state of size
[nof_state_parameters x nof_state_parameters]</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>forecast_steps</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="int">int</span>, <span title="list">list</span>, <span title="numpy.ndarray">ndarray</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Steps ahead to forecast</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>r_t_k</code></td>            <td>
                  <code><span title="numpy.array">array</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Forecast values of estimated prior state covariance of the size
[nof_state_parameters x nof_state_parameters x size(forecast_steps)]</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
<td><code>q_t_k</code></td>            <td>
                  <code><span title="numpy.array">array</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Forecast values of estimated observation covariance of the size
[nof_observables x nof_observables x size(forecast_steps)]</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>src/pyelq/dlm.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">forecast_covariance</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">c_matrix</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">forecast_steps</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Perform forecasting of the state and observation covariance parameters.</span>

<span class="sd">    Following Harrison and West (2nd ed) Chapter 4.4 (Forecast Distributions), assuming F, G, V and W are</span>
<span class="sd">    constant over time.</span>
<span class="sd">    Note that in the output the third axis of the output arrays is the forecast dimension consistent with the</span>
<span class="sd">    forecast steps input, all forecast steps contained in the forecast steps argument are returned.</span>
<span class="sd">    sum_g_w_g is initialized as G^k @ W @ G^k for k==0, hence we initialize as W</span>
<span class="sd">    Because of zero based indexing, in the for loop i==1 means 2-step ahead forecast which requires element</span>
<span class="sd">    (i+1) of the g_power attribute as the third dimension serves as the actual power of the G matrix</span>

<span class="sd">    Args:</span>
<span class="sd">        c_matrix (np.ndarray): Current posterior covariance estimate for the state of size</span>
<span class="sd">            [nof_state_parameters x nof_state_parameters]</span>
<span class="sd">        forecast_steps (Union[int, list, np.ndarray], optional): Steps ahead to forecast</span>

<span class="sd">    Returns:</span>
<span class="sd">        r_t_k (np.array): Forecast values of estimated prior state covariance of the size</span>
<span class="sd">            [nof_state_parameters x nof_state_parameters x size(forecast_steps)]</span>
<span class="sd">        q_t_k (np.array): Forecast values of estimated observation covariance of the size</span>
<span class="sd">            [nof_observables x nof_observables x size(forecast_steps)]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">min_forecast</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">amin</span><span class="p">(</span><span class="n">forecast_steps</span><span class="p">)</span>
    <span class="n">max_forecast</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="n">forecast_steps</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">min_forecast</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Minimum forecast should be &gt;= 1, currently it is </span><span class="si">{</span><span class="n">min_forecast</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">forecast_steps</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">forecast_steps</span> <span class="o">=</span> <span class="p">[</span><span class="n">forecast_steps</span><span class="p">]</span>

    <span class="n">sum_g_w_g</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">nof_state_parameters</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nof_state_parameters</span><span class="p">,</span> <span class="n">max_forecast</span><span class="p">))</span>
    <span class="n">sum_g_w_g</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_matrix</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_forecast</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">sum_g_w_g</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">sum_g_w_g</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">g_power</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_matrix</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">g_power</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">T</span>
        <span class="p">)</span>

    <span class="n">r_t_k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dstack</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">g_power</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">step</span><span class="p">]</span> <span class="o">@</span> <span class="n">c_matrix</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">g_power</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">step</span><span class="p">]</span><span class="o">.</span><span class="n">T</span> <span class="o">+</span> <span class="n">sum_g_w_g</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">step</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">forecast_steps</span>
        <span class="p">]</span>
    <span class="p">)</span>
    <span class="n">q_t_k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dstack</span><span class="p">(</span>
        <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">f_matrix</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">r_t_k</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">idx</span><span class="p">]</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_matrix</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_matrix</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">r_t_k</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])]</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">r_t_k</span><span class="p">,</span> <span class="n">q_t_k</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="pyelq.dlm.DLM.update_posterior" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">update_posterior</span><span class="p">(</span><span class="n">a_t</span><span class="p">,</span> <span class="n">r_matrix_t</span><span class="p">,</span> <span class="n">q_matrix_t</span><span class="p">,</span> <span class="n">error</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Update of the posterior mean and covariance of the state.</p>
<p>Following Harrison and West (2nd ed) Chapter 4.4 (Forecast Distributions), assuming F, G, V and W are
constant over time.
We are using a solver instead of calculating the inverse of Q directly
Setting inf values in Q equal to 0 after the solver function for computational issues, otherwise we would
get 0 * inf = nan, where we want the result to be 0.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>a_t</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Current prior mean of the state of size [nof_state_parameters x 1]</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>r_matrix_t</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Current prior covariance of the state of size [nof_state_parameters x nof_state_parameters]</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>q_matrix_t</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Current one step ahead forecast covariance estimate of the observations of size [nof_observables x nof_observables]</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>error</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Error associated with the one step ahead forecast (observation - forecast) of size [nof_observables x 1]</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>m_t</code></td>            <td>
                  <code><span title="numpy.array">array</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Posterior mean estimate of the state of size [nof_state_parameters x 1]</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
<td><code>c_matrix</code></td>            <td>
                  <code><span title="numpy.array">array</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Posterior covariance estimate of the state of size [nof_state_parameters x nof_state_parameters]</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>src/pyelq/dlm.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">update_posterior</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">a_t</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">r_matrix_t</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">q_matrix_t</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">error</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Update of the posterior mean and covariance of the state.</span>

<span class="sd">    Following Harrison and West (2nd ed) Chapter 4.4 (Forecast Distributions), assuming F, G, V and W are</span>
<span class="sd">    constant over time.</span>
<span class="sd">    We are using a solver instead of calculating the inverse of Q directly</span>
<span class="sd">    Setting inf values in Q equal to 0 after the solver function for computational issues, otherwise we would</span>
<span class="sd">    get 0 * inf = nan, where we want the result to be 0.</span>

<span class="sd">    Args:</span>
<span class="sd">        a_t (np.ndarray): Current prior mean of the state of size [nof_state_parameters x 1]</span>
<span class="sd">        r_matrix_t (np.ndarray): Current prior covariance of the state of size [nof_state_parameters x nof_state_parameters]</span>
<span class="sd">        q_matrix_t (np.ndarray): Current one step ahead forecast covariance estimate of the observations of size [nof_observables x nof_observables]</span>
<span class="sd">        error (np.ndarray): Error associated with the one step ahead forecast (observation - forecast) of size [nof_observables x 1]</span>

<span class="sd">    Returns:</span>
<span class="sd">        m_t (np.array): Posterior mean estimate of the state of size [nof_state_parameters x 1]</span>
<span class="sd">        c_matrix (np.array): Posterior covariance estimate of the state of size [nof_state_parameters x nof_state_parameters]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">nof_state_parameters</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">a_matrix_t</span> <span class="o">=</span> <span class="n">r_matrix_t</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_matrix</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">q_matrix_t</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">a_matrix_t</span> <span class="o">=</span> <span class="n">r_matrix_t</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">q_matrix_t</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_matrix</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
    <span class="n">m_t</span> <span class="o">=</span> <span class="n">a_t</span> <span class="o">+</span> <span class="n">a_matrix_t</span> <span class="o">@</span> <span class="n">error</span>
    <span class="n">q_matrix_t</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">q_matrix_t</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">c_matrix</span> <span class="o">=</span> <span class="n">r_matrix_t</span> <span class="o">-</span> <span class="n">a_matrix_t</span> <span class="o">@</span> <span class="n">q_matrix_t</span> <span class="o">@</span> <span class="n">a_matrix_t</span><span class="o">.</span><span class="n">T</span>

    <span class="k">return</span> <span class="n">m_t</span><span class="p">,</span> <span class="n">c_matrix</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="pyelq.dlm.DLM.dlm_full_update" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">dlm_full_update</span><span class="p">(</span><span class="n">new_observation</span><span class="p">,</span> <span class="n">current_mean_state</span><span class="p">,</span> <span class="n">current_cov_state</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;learn&#39;</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Perform 1 step of the full DLM update.</p>
<p>Following Harrison and West (2nd ed) we perform all steps to update the entire DLM model and obtain new
estimates for all parameters involved, including nan value handling.
When mode == 'learn' the parameters are updated, when mode == 'ignore' the current observation is ignored and
the posterior is set equal to the prior
When no observation is present (i.e. a nan value) we let the covariance (V matrix) for that particular sensor
such that we set the variance of that sensor for that time instance to infinity and set all cross (covariance)
terms to 0. Instead of changing this in the V matrix, we simply adjust the Q matrix accordingly. Effectively,
we set the posterior equal to the prior for that particular sensor and the uncertainty associated with the new
forecast gets increased. We set the error equal to zero for computational issues, first but finally set it equal
to nan in the end.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>new_observation</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>New observations to use in the updating of the estimates of size [nof_observables x 1]</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>current_mean_state</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Current mean estimate for the state of size [nof_state_parameters x 1]</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>current_cov_state</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Current covariance estimate for the state of size [nof_state_parameters x nof_state_parameters]</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mode</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>String indicating whether the DLM needs to be updated using the new observation or not. Currently, <code>learn</code> and <code>ignore</code> are implemented</p>
              </div>
            </td>
            <td>
                  <code>&#39;learn&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>new_mean_state</code></td>            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>New mean estimate for the state of size [nof_state_parameters x 1]</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
<td><code>new_cov_state</code></td>            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>New covariance estimate for the state of size [nof_state_parameters x nof_state_parameters]</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
<td><code>error</code></td>            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Error between the observation and the forecast (observation - forecast) of size [nof_observables x 1]</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>src/pyelq/dlm.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">dlm_full_update</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">new_observation</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">current_mean_state</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">current_cov_state</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;learn&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Perform 1 step of the full DLM update.</span>

<span class="sd">    Following Harrison and West (2nd ed) we perform all steps to update the entire DLM model and obtain new</span>
<span class="sd">    estimates for all parameters involved, including nan value handling.</span>
<span class="sd">    When mode == &#39;learn&#39; the parameters are updated, when mode == &#39;ignore&#39; the current observation is ignored and</span>
<span class="sd">    the posterior is set equal to the prior</span>
<span class="sd">    When no observation is present (i.e. a nan value) we let the covariance (V matrix) for that particular sensor</span>
<span class="sd">    such that we set the variance of that sensor for that time instance to infinity and set all cross (covariance)</span>
<span class="sd">    terms to 0. Instead of changing this in the V matrix, we simply adjust the Q matrix accordingly. Effectively,</span>
<span class="sd">    we set the posterior equal to the prior for that particular sensor and the uncertainty associated with the new</span>
<span class="sd">    forecast gets increased. We set the error equal to zero for computational issues, first but finally set it equal</span>
<span class="sd">    to nan in the end.</span>

<span class="sd">    Args:</span>
<span class="sd">        new_observation (np.ndarray): New observations to use in the updating of the estimates of size [nof_observables x 1]</span>
<span class="sd">        current_mean_state (np.ndarray):  Current mean estimate for the state of size [nof_state_parameters x 1]</span>
<span class="sd">        current_cov_state (np.ndarray):  Current covariance estimate for the state of size [nof_state_parameters x nof_state_parameters]</span>
<span class="sd">        mode (str, optional): String indicating whether the DLM needs to be updated using the new observation or not. Currently, `learn` and `ignore` are implemented</span>

<span class="sd">    Returns:</span>
<span class="sd">        new_mean_state (np.ndarray): New mean estimate for the state of size [nof_state_parameters x 1]</span>
<span class="sd">        new_cov_state (np.ndarray): New covariance estimate for the state of size [nof_state_parameters x nof_state_parameters]</span>
<span class="sd">        error (np.ndarray): Error between the observation and the forecast (observation - forecast) of size [nof_observables x 1]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">a_t</span><span class="p">,</span> <span class="n">f_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forecast_mean</span><span class="p">(</span><span class="n">current_mean_state</span><span class="p">,</span> <span class="n">forecast_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">r_matrix_t</span><span class="p">,</span> <span class="n">q_matrix_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forecast_covariance</span><span class="p">(</span><span class="n">current_cov_state</span><span class="p">,</span> <span class="n">forecast_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">error</span> <span class="o">=</span> <span class="n">new_observation</span> <span class="o">-</span> <span class="n">f_t</span>

    <span class="n">nan_bool</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">new_observation</span><span class="p">)</span>
    <span class="n">nan_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="n">nan_bool</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">nan_bool</span><span class="p">):</span>
        <span class="n">q_matrix_t</span><span class="p">[</span><span class="n">nan_idx</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_matrix</span><span class="p">[</span><span class="n">nan_idx</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">q_matrix_t</span><span class="p">[:,</span> <span class="n">nan_idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_matrix</span><span class="p">[:,</span> <span class="n">nan_idx</span><span class="p">]</span>
        <span class="n">q_matrix_t</span><span class="p">[</span><span class="n">nan_idx</span><span class="p">,</span> <span class="n">nan_idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="n">error</span><span class="p">[</span><span class="n">nan_idx</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;learn&quot;</span><span class="p">:</span>
        <span class="n">new_mean_state</span><span class="p">,</span> <span class="n">new_cov_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_posterior</span><span class="p">(</span><span class="n">a_t</span><span class="p">,</span> <span class="n">r_matrix_t</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">q_matrix_t</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">error</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;ignore&quot;</span><span class="p">:</span>
        <span class="n">new_mean_state</span> <span class="o">=</span> <span class="n">a_t</span>
        <span class="n">new_cov_state</span> <span class="o">=</span> <span class="n">r_matrix_t</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mode </span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s2"> not implemented&quot;</span><span class="p">)</span>

    <span class="n">error</span><span class="p">[</span><span class="n">nan_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

    <span class="k">return</span> <span class="n">new_mean_state</span><span class="p">,</span> <span class="n">new_cov_state</span><span class="p">,</span> <span class="n">error</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="pyelq.dlm.DLM.calculate_mahalanobis_distance" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">calculate_mahalanobis_distance</span><span class="p">(</span><span class="n">new_observations</span><span class="p">,</span> <span class="n">current_mean_state</span><span class="p">,</span> <span class="n">current_cov_state</span><span class="p">,</span> <span class="n">forecast_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_statistics</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Calculate the mahalanobis distance.</p>
<p>Calculating the Mahalanobis distance which is defined as error.T @ covariance^(-1) @ error
The error is flatted in row-major (C-style) This returns the stacked rows, which in our case is the errors per
observation parameter stacked and this is exactly what we want: array([[1, 2], [3, 4]]).reshape((-1, 1),
order='C') becomes column array([1, 2 3, 4])
Using a solve method instead of calculating inverse matrices directly
When calculating mhd_per_obs_param we use the partial result and reshape the temporary output such that we can
sum the correct elements associated with the same observable together
When no observation is present (i.e. a nan value) we let the covariance (V matrix) for that particular sensor
such that we set the variance of that sensor for that time instance to infinity and set all cross (covariance)
terms to 0. Instead of changing this in the V matrix, we simply adjust the Q matrix accordingly. Effectively,
we set the posterior equal to the prior for that particular sensor and the uncertainty associated with the new
forecast gets increased. We set the error equal to zero for computational issues, but this does decrease the
number of degrees of freedom for that particular Mahalanobis distance calculation, basically decreasing the
Mahalanobis distance. We allow the option to output the number of degrees of freedom and chi2 statistic which
allows to take this decrease in degrees of freedom into account.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>new_observations</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>New observations to use in the calculation of the mahalanobis distance of
size [nof_observables x forecast_steps]</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>current_mean_state</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Current mean estimate for the state of size [nof_state_parameters x 1]</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>current_cov_state</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Current covariance estimate for the state of size
[nof_state_parameters x nof_state_parameters]</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>forecast_steps</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of steps ahead to forecast and use in the mahalanobis distance
calculation</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_statistics</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Boolean to return used degrees of freedom and chi2 statistic</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>
        


            <details class="quote">
              <summary>Source code in <code>src/pyelq/dlm.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">calculate_mahalanobis_distance</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">new_observations</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">current_mean_state</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">current_cov_state</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">forecast_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">return_statistics</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Calculate the mahalanobis distance.</span>

<span class="sd">    Calculating the Mahalanobis distance which is defined as error.T @ covariance^(-1) @ error</span>
<span class="sd">    The error is flatted in row-major (C-style) This returns the stacked rows, which in our case is the errors per</span>
<span class="sd">    observation parameter stacked and this is exactly what we want: array([[1, 2], [3, 4]]).reshape((-1, 1),</span>
<span class="sd">    order=&#39;C&#39;) becomes column array([1, 2 3, 4])</span>
<span class="sd">    Using a solve method instead of calculating inverse matrices directly</span>
<span class="sd">    When calculating mhd_per_obs_param we use the partial result and reshape the temporary output such that we can</span>
<span class="sd">    sum the correct elements associated with the same observable together</span>
<span class="sd">    When no observation is present (i.e. a nan value) we let the covariance (V matrix) for that particular sensor</span>
<span class="sd">    such that we set the variance of that sensor for that time instance to infinity and set all cross (covariance)</span>
<span class="sd">    terms to 0. Instead of changing this in the V matrix, we simply adjust the Q matrix accordingly. Effectively,</span>
<span class="sd">    we set the posterior equal to the prior for that particular sensor and the uncertainty associated with the new</span>
<span class="sd">    forecast gets increased. We set the error equal to zero for computational issues, but this does decrease the</span>
<span class="sd">    number of degrees of freedom for that particular Mahalanobis distance calculation, basically decreasing the</span>
<span class="sd">    Mahalanobis distance. We allow the option to output the number of degrees of freedom and chi2 statistic which</span>
<span class="sd">    allows to take this decrease in degrees of freedom into account.</span>

<span class="sd">    Args:</span>
<span class="sd">        new_observations (np.ndarray): New observations to use in the calculation of the mahalanobis distance of</span>
<span class="sd">            size [nof_observables x forecast_steps]</span>
<span class="sd">        current_mean_state (np.ndarray): Current mean estimate for the state of size [nof_state_parameters x 1]</span>
<span class="sd">        current_cov_state (np.ndarray): Current covariance estimate for the state of size</span>
<span class="sd">            [nof_state_parameters x nof_state_parameters]</span>
<span class="sd">        forecast_steps (int, optional): Number of steps ahead to forecast and use in the mahalanobis distance</span>
<span class="sd">            calculation</span>
<span class="sd">        return_statistics (bool, optional): Boolean to return used degrees of freedom and chi2 statistic</span>
<span class="sd">    Returns:</span>
<span class="sd">        mhd_overall (float): mahalanobis distance over all observables</span>
<span class="sd">        mhd_per_obs_param (np.ndarray): mahalanobis distance per observation parameter of size [nof_observables, 1]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">forecast_steps</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s2">&quot;Forecast steps should be a positive integer&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">new_observations</span><span class="o">.</span><span class="n">size</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">nof_observables</span> <span class="o">!=</span> <span class="n">forecast_steps</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s2">&quot;Sizes of new observations and forecast steps are not aligning&quot;</span><span class="p">)</span>

    <span class="n">_</span><span class="p">,</span> <span class="n">f_t_k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forecast_mean</span><span class="p">(</span><span class="n">current_mean_state</span><span class="p">,</span> <span class="n">forecast_steps</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">forecast_steps</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">new_observations</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">f_t_k</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s2">&quot;Dimensions of new_observations are not aligning with dimensions of forecast&quot;</span><span class="p">)</span>

    <span class="n">error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">new_observations</span><span class="p">,</span> <span class="n">f_t_k</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">)</span>

    <span class="n">r_t_k</span><span class="p">,</span> <span class="n">q_t_k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forecast_covariance</span><span class="p">(</span><span class="n">current_cov_state</span><span class="p">,</span> <span class="n">forecast_steps</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">forecast_steps</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">nan_bool</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">new_observations</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">nan_bool</span><span class="p">):</span>
        <span class="n">nan_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="n">nan_bool</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">nan_idx</span><span class="p">:</span>
            <span class="n">q_t_k</span><span class="p">[</span><span class="n">value</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">:,</span> <span class="n">value</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_matrix</span><span class="p">[</span><span class="n">value</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">:]</span>
            <span class="n">q_t_k</span><span class="p">[:,</span> <span class="n">value</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">value</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_matrix</span><span class="p">[:,</span> <span class="n">value</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>

        <span class="n">q_t_k</span><span class="p">[</span><span class="n">nan_idx</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">nan_idx</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">nan_idx</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="n">error</span><span class="p">[</span><span class="n">nan_bool</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">if</span> <span class="n">forecast_steps</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">full_covariance</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_full_covariance</span><span class="p">(</span><span class="n">r_t_k</span><span class="o">=</span><span class="n">r_t_k</span><span class="p">,</span> <span class="n">q_t_k</span><span class="o">=</span><span class="n">q_t_k</span><span class="p">,</span> <span class="n">forecast_steps</span><span class="o">=</span><span class="n">forecast_steps</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">full_covariance</span> <span class="o">=</span> <span class="n">q_t_k</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span>

    <span class="n">mhd_overall</span> <span class="o">=</span> <span class="n">mahalanobis_distance</span><span class="p">(</span><span class="n">error</span><span class="o">=</span><span class="n">error</span><span class="p">,</span> <span class="n">cov_matrix</span><span class="o">=</span><span class="n">full_covariance</span><span class="p">)</span>
    <span class="n">mhd_per_obs_param</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">nof_observables</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">i_obs</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nof_observables</span><span class="p">):</span>
        <span class="n">ind_hrz</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">forecast_steps</span><span class="p">))</span> <span class="o">+</span> <span class="n">i_obs</span> <span class="o">*</span> <span class="n">forecast_steps</span>
        <span class="n">mhd_per_obs_param</span><span class="p">[</span><span class="n">i_obs</span><span class="p">]</span> <span class="o">=</span> <span class="n">mahalanobis_distance</span><span class="p">(</span>
            <span class="n">error</span><span class="o">=</span><span class="n">error</span><span class="p">[</span><span class="n">ind_hrz</span><span class="p">],</span> <span class="n">cov_matrix</span><span class="o">=</span><span class="n">full_covariance</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ix_</span><span class="p">(</span><span class="n">ind_hrz</span><span class="p">,</span> <span class="n">ind_hrz</span><span class="p">)]</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">nof_observables</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">mhd_per_obs_param</span> <span class="o">=</span> <span class="n">mhd_per_obs_param</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">return_statistics</span><span class="p">:</span>
        <span class="n">dof_per_obs_param</span> <span class="o">=</span> <span class="p">(</span><span class="n">nan_bool</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">nan_bool</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">nof_observables</span><span class="p">,</span> <span class="mi">1</span>
        <span class="p">)</span>
        <span class="n">dof_overall</span> <span class="o">=</span> <span class="n">dof_per_obs_param</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">chi2_cdf_per_obs_param</span> <span class="o">=</span> <span class="n">chi2</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">mhd_per_obs_param</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">dof_per_obs_param</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">nof_observables</span><span class="p">,</span> <span class="mi">1</span>
        <span class="p">)</span>
        <span class="n">chi2_cdf_overall</span> <span class="o">=</span> <span class="n">chi2</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">mhd_overall</span><span class="p">,</span> <span class="n">dof_overall</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">(</span>
            <span class="n">mhd_overall</span><span class="p">,</span>
            <span class="n">mhd_per_obs_param</span><span class="p">,</span>
            <span class="n">dof_overall</span><span class="p">,</span>
            <span class="n">dof_per_obs_param</span><span class="p">,</span>
            <span class="n">chi2_cdf_overall</span><span class="p">,</span>
            <span class="n">chi2_cdf_per_obs_param</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">mhd_overall</span><span class="p">,</span> <span class="n">mhd_per_obs_param</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="pyelq.dlm.DLM.create_full_covariance" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">create_full_covariance</span><span class="p">(</span><span class="n">r_t_k</span><span class="p">,</span> <span class="n">q_t_k</span><span class="p">,</span> <span class="n">forecast_steps</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Helper function to construct the full covariance matrix.</p>
<p>Following Harrison and West (2nd ed) Chapter 4.4 (Forecast distributions) Theorem 4.2 and corollary 4.2
we construct the full covariance matrix. This full covariance matrix is the covariance matrix of all forecasted
observations with respect to each other. Hence, it's COV[Y_{t+k}, Y_{t+j}] with j and k 1&lt;=j,k&lt;=forecast steps
input argument and Y_{t+k} the k step ahead forecast of the observation at time t</p>
<p>The matrix is build up using the different blocks for different covariances between observations i and j.
The diagonals of each block are calculated first as q_t_k[i, j, :].
Next the i, j-th (lower triangular) entry of the m, n-th block is calculated as
(F.T @ G^(i-j) r_t_k[:, :, j] @ F)[i, j]
Next each upper triangular part of each lower diagonal block is calculated and next the entire upper triangular
part of the full matrix is calculated</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>r_t_k</code>
            </td>
            <td>
                  <code><span title="numpy.array">array</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Forecast values of estimated prior state covariance of the size
[nof_state_parameters x nof_state_parameters x forecast_steps]</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>q_t_k</code>
            </td>
            <td>
                  <code><span title="numpy.array">array</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Forecast values of estimated observation covariance of the size
[nof_observables x nof_observables x forecast_steps]</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>forecast_steps</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Maximum number of steps ahead to forecast and use all of those in the mahalanobis
distance calculation</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>full_covariance</code></td>            <td>
                  <code><span title="numpy.array">array</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Full covariance matrix of all forecasted observations with respect to each other</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
<td></td>            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>having size [(nof_observables * forecast_steps) X (nof_observables * forecast_steps)]</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>src/pyelq/dlm.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">create_full_covariance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">r_t_k</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">q_t_k</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">forecast_steps</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Helper function to construct the full covariance matrix.</span>

<span class="sd">    Following Harrison and West (2nd ed) Chapter 4.4 (Forecast distributions) Theorem 4.2 and corollary 4.2</span>
<span class="sd">    we construct the full covariance matrix. This full covariance matrix is the covariance matrix of all forecasted</span>
<span class="sd">    observations with respect to each other. Hence, it&#39;s COV[Y_{t+k}, Y_{t+j}] with j and k 1&lt;=j,k&lt;=forecast steps</span>
<span class="sd">    input argument and Y_{t+k} the k step ahead forecast of the observation at time t</span>

<span class="sd">    The matrix is build up using the different blocks for different covariances between observations i and j.</span>
<span class="sd">    The diagonals of each block are calculated first as q_t_k[i, j, :].</span>
<span class="sd">    Next the i, j-th (lower triangular) entry of the m, n-th block is calculated as</span>
<span class="sd">    (F.T @ G^(i-j) r_t_k[:, :, j] @ F)[i, j]</span>
<span class="sd">    Next each upper triangular part of each lower diagonal block is calculated and next the entire upper triangular</span>
<span class="sd">    part of the full matrix is calculated</span>

<span class="sd">    Args:</span>
<span class="sd">        r_t_k (np.array): Forecast values of estimated prior state covariance of the size</span>
<span class="sd">            [nof_state_parameters x nof_state_parameters x forecast_steps]</span>
<span class="sd">        q_t_k (np.array): Forecast values of estimated observation covariance of the size</span>
<span class="sd">            [nof_observables x nof_observables x forecast_steps]</span>
<span class="sd">        forecast_steps (int): Maximum number of steps ahead to forecast and use all of those in the mahalanobis</span>
<span class="sd">            distance calculation</span>

<span class="sd">    Returns:</span>
<span class="sd">        full_covariance (np.array): Full covariance matrix of all forecasted observations with respect to each other</span>
<span class="sd">        having size [(nof_observables * forecast_steps) X (nof_observables * forecast_steps)]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">full_covariance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">forecast_steps</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">nof_observables</span><span class="p">,</span> <span class="n">forecast_steps</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">nof_observables</span><span class="p">))</span>
    <span class="n">base_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">forecast_steps</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">block_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nof_observables</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">block_j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">block_i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">block_rows</span> <span class="o">=</span> <span class="n">base_idx</span> <span class="o">+</span> <span class="n">block_i</span> <span class="o">*</span> <span class="n">forecast_steps</span>
            <span class="n">block_cols</span> <span class="o">=</span> <span class="n">base_idx</span> <span class="o">+</span> <span class="n">block_j</span> <span class="o">*</span> <span class="n">forecast_steps</span>
            <span class="n">full_covariance</span><span class="p">[</span><span class="n">block_rows</span><span class="p">,</span> <span class="n">block_cols</span><span class="p">]</span> <span class="o">=</span> <span class="n">q_t_k</span><span class="p">[</span><span class="n">block_i</span><span class="p">,</span> <span class="n">block_j</span><span class="p">,</span> <span class="p">:]</span>

    <span class="n">temp_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nof_observables</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">sub_i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stop</span><span class="o">=</span><span class="n">forecast_steps</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">sub_row</span> <span class="o">=</span> <span class="n">temp_idx</span> <span class="o">*</span> <span class="n">forecast_steps</span> <span class="o">+</span> <span class="n">sub_i</span>
        <span class="k">for</span> <span class="n">sub_j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">sub_i</span><span class="p">):</span>
            <span class="n">sub_col</span> <span class="o">=</span> <span class="n">temp_idx</span> <span class="o">*</span> <span class="n">forecast_steps</span> <span class="o">+</span> <span class="n">sub_j</span>
            <span class="n">sub_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ix_</span><span class="p">(</span><span class="n">sub_row</span><span class="p">,</span> <span class="n">sub_col</span><span class="p">)</span>
            <span class="n">full_covariance</span><span class="p">[</span><span class="n">sub_idx</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">f_matrix</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">g_power</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">sub_i</span> <span class="o">-</span> <span class="n">sub_j</span><span class="p">]</span> <span class="o">@</span> <span class="n">r_t_k</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">sub_j</span><span class="p">]</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_matrix</span>
            <span class="p">)</span>

    <span class="k">for</span> <span class="n">block_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nof_observables</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">block_j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">block_i</span><span class="p">):</span>
            <span class="n">block_rows</span> <span class="o">=</span> <span class="n">base_idx</span> <span class="o">+</span> <span class="n">block_i</span> <span class="o">*</span> <span class="n">forecast_steps</span>
            <span class="n">block_cols</span> <span class="o">=</span> <span class="n">base_idx</span> <span class="o">+</span> <span class="n">block_j</span> <span class="o">*</span> <span class="n">forecast_steps</span>
            <span class="n">block_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ix_</span><span class="p">(</span><span class="n">block_rows</span><span class="p">,</span> <span class="n">block_cols</span><span class="p">)</span>
            <span class="n">full_covariance</span><span class="p">[</span><span class="n">block_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">full_covariance</span><span class="p">[</span><span class="n">block_idx</span><span class="p">]</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="n">full_covariance</span><span class="p">[</span><span class="n">block_idx</span><span class="p">],</span> <span class="n">k</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>

    <span class="n">full_covariance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="n">full_covariance</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="n">full_covariance</span><span class="p">,</span> <span class="n">k</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>

    <span class="k">return</span> <span class="n">full_covariance</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>


<div class="doc doc-object doc-function">


<h2 id="pyelq.dlm.mahalanobis_distance" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mahalanobis_distance</span><span class="p">(</span><span class="n">error</span><span class="p">,</span> <span class="n">cov_matrix</span><span class="p">)</span></code>

</h2>


    <div class="doc doc-contents ">

        <p>Calculate Mahalanobis distance for multivariate observations.</p>
<p>m = e.T @ inv(cov) @ e
Sometimes the solution does not exist when np.inf value is present in cov_matrix (computational limitations?)
Hence, we set it to a large value instead</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>error</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>n x p   observation error</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>cov_matrix</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>p x p covariance matrix</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>np.ndarray: n x 1  mahalanobis distance score for each observation</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>src/pyelq/dlm.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">mahalanobis_distance</span><span class="p">(</span><span class="n">error</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">cov_matrix</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Calculate Mahalanobis distance for multivariate observations.</span>

<span class="sd">    m = e.T @ inv(cov) @ e</span>
<span class="sd">    Sometimes the solution does not exist when np.inf value is present in cov_matrix (computational limitations?)</span>
<span class="sd">    Hence, we set it to a large value instead</span>

<span class="sd">    Args:</span>
<span class="sd">        error (np.ndarray):  n x p   observation error</span>
<span class="sd">        cov_matrix (np.ndarray): p x p covariance matrix</span>

<span class="sd">    Returns:</span>
<span class="sd">        np.ndarray: n x 1  mahalanobis distance score for each observation</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">cov_matrix</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">error</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">cov_matrix</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="n">partial_solution</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">cov_matrix</span><span class="p">,</span> <span class="n">error</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">partial_solution</span><span class="p">)):</span>
        <span class="n">cov_matrix</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">cov_matrix</span><span class="p">)]</span> <span class="o">=</span> <span class="mf">1e100</span>
        <span class="n">partial_solution</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">cov_matrix</span><span class="p">,</span> <span class="n">error</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">error</span> <span class="o">*</span> <span class="n">partial_solution</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["content.code.annotate", "content.code.copy", "content.code.select", "content.tabs.link", "content.tooltips", "navigation.indexes", "navigation.instant", "navigation.tabs", "navigation.top", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../../assets/javascripts/workers/search.d50fe291.min.js", "tags": {"Pipelines": "pipelines"}, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.56ea9cef.min.js"></script>
      
    
  </body>
</html>